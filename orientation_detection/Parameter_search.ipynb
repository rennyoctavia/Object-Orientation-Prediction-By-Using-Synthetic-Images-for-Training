{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is utilize for parameter tuning, using Keras RandomSearchCV and GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the CNN module to be wrapped with Scikit_learn wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_model(size = 64,target_type='vectorOrientations',optimizer='adam',dropout_rate1=0.0,dropout_rate2=0.0, fc1 = 512, fc2 = 64,padding1 = 'valid',padding2='valid'):\n",
    "    \n",
    "    if target_type == 'quaternions':\n",
    "        output_layer = 4\n",
    "    else:\n",
    "        output_layer = 6\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Set up Convolutional layers\n",
    "    model.add(Conv2D(96, (11, 11),padding=padding1, input_shape=(size, size, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(384, (5, 5), padding = padding2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Set up Fully Connected layers\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(fc1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=dropout_rate1))\n",
    "    model.add(Dense(fc2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=dropout_rate2))\n",
    "    model.add(Dense(output_layer))\n",
    "    model.add(Activation('linear')) #due to this is a regression problem\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=customized_mse,\n",
    "    optimizer=optimizer)#,\n",
    "    #metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized_mse function\n",
    "- modification of standard MSE, adding scaling of the vedctor to the unit length\n",
    "- take input of true test target and predictions\n",
    "- return the mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse(y_true,y_pred):\n",
    "    vector_1 = y_pred[:,:3]\n",
    "    vector_2 = y_pred[:,3:]\n",
    "\n",
    "    # To normalize the predictions vectors to have length of 1\n",
    "    normalized_vector_1 = tf.divide(vector_1,tf.sqrt(tf.reduce_sum(tf.square(vector_1),1,keepdims=True)))\n",
    "    normalized_vector_2 = tf.divide(vector_2,tf.sqrt(tf.reduce_sum(tf.square(vector_2),1,keepdims=True)))\n",
    "    normalized_y_pred = tf.concat([normalized_vector_1, normalized_vector_2], axis=1)\n",
    "    return tf.reduce_mean(tf.square(tf.subtract(normalized_y_pred,y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history,optimizer):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.xlabel(\"Epoch\",fontsize=12)\n",
    "    plt.ylabel(\"Loss\",fontsize=12)\n",
    "    plt.title(\"Optimizer: \"+optimizer,fontsize=12,fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 1500\n",
    "image_size = 64\n",
    "target_type = 'vectorOrientations'\n",
    "\n",
    "rendered_images = get_images(num_images,image_size)\n",
    "    \n",
    "# convert into x_train, xVal, yTrain and yVal\n",
    "xTrain, xVal, yTrain, yVal= get_train_val(rendered_images,target_type)\n",
    "    \n",
    "# Reshape the train and validation set\n",
    "len_train = len(xTrain)\n",
    "len_val = len(xVal)\n",
    "xTrain = np.array(xTrain).reshape(len_train,image_size,image_size,3)\n",
    "xVal = np.array(xVal).reshape(len_val,image_size,image_size,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters and scikit_learn wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(get_CNN_model)\n",
    "\n",
    "param_distribs = {\n",
    "    \"optimizer\": ['adam','adadelta','rmsprop','sgd','adagrad','nadam','adamax'],\n",
    "    \"dropout_rate1\": [0,0.2,0.3,0.5],\n",
    "    \"dropout_rate2\": [0,0.2,0.3,0.5],\n",
    "    \"epochs\": [30,50,100],\n",
    "    \"batch_size\":[20,30,40,64,128],\n",
    "    \"fc1\": [512,1024,256],\n",
    "    \"fc2\": [64,256,32],\n",
    "    \"padding1\":['valid','same'],\n",
    "    \"padding2\":['valid','same']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv = RandomizedSearchCV(estimator = keras_reg, param_distributions = param_distribs, n_jobs=1, n_iter=5, cv=3, verbose=2)\n",
    "random_search_cv.fit(xTrain, yTrain,\n",
    "                  validation_data=(xVal, yVal),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the images for testing (on later stage should get images from Nil's module)\n",
    "image_test = get_images(200,64)\n",
    "x_test = np.array(image_test['images'])\n",
    "y_test = np.array([np.concatenate(x) for x in image_test['vectorOrientations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnd = random_search_cv.best_estimator_.model\n",
    "model_rnd.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnd.save(\"renny/tuned_model_rnd_1_12April.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv = GridSearchCV(estimator = keras_reg, param_grid = param_distribs, verbose=2)\n",
    "grid_search_cv.fit(xTrain, yTrain,\n",
    "                  validation_data=(xVal, yVal),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search of Learning rates parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "optimizers = ['adam','adadelta','rmsprop','sgd','adagrad','nadam','adamax']\n",
    "histories = []\n",
    "for optimizer in optimizers:\n",
    "    model = get_CNN_model(optimizer= optimizer)\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10)]\n",
    "    history = model.fit(xTrain, yTrain,\n",
    "                        validation_data=(xVal, yVal), epochs=50,batch_size=50,\n",
    "                        callbacks=callbacks)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer, history in zip(optimizers, histories):\n",
    "    plot_learning_curves(history,optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,40))\n",
    "\n",
    "n_optimizers = len(optimizers)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(n_optimizers,1,1)\n",
    "ax.plot(range(1,len(histories[0].history['loss'])+1), histories[0].history['val_loss'],label='val_loss')\n",
    "ax.plot(range(1,len(histories[0].history['loss'])+1), histories[0].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[0],fontweight=\"bold\")\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.grid()\n",
    "plt.gca().set_ylim(0, 1)\n",
    "ax.legend()\n",
    "    \n",
    "ax1 = fig.add_subplot(n_optimizers,1,2)\n",
    "ax1.plot(range(1,len(histories[1].history['loss'])+1), histories[1].history['val_loss'],label='val_loss')\n",
    "ax1.plot(range(1,len(histories[1].history['loss'])+1), histories[1].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[1],fontweight=\"bold\")\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "ax1.legend()\n",
    "    \n",
    "ax2 = fig.add_subplot(n_optimizers,1,3)\n",
    "ax2.plot(range(1,len(histories[2].history['loss'])+1), histories[2].history['val_loss'],label='val_loss')\n",
    "ax2.plot(range(1,len(histories[2].history['loss'])+1), histories[2].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[2],fontweight=\"bold\")\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "ax2.legend()\n",
    "        \n",
    "ax3 = fig.add_subplot(n_optimizers,1,4)\n",
    "ax3.plot(range(1,len(histories[3].history['loss'])+1), histories[3].history['val_loss'],label='val_loss')\n",
    "ax3.plot(range(1,len(histories[3].history['loss'])+1), histories[3].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[0],fontweight=\"bold\")\n",
    "ax3.set_ylabel('Loss')\n",
    "ax3.set_xlabel('epoch')\n",
    "ax3.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "ax3.legend()\n",
    "        \n",
    "ax4 = fig.add_subplot(n_optimizers,1,5)\n",
    "ax4.plot(range(1,len(histories[4].history['loss'])+1), histories[4].history['val_loss'],label='val_loss')\n",
    "ax4.plot(range(1,len(histories[4].history['loss'])+1), histories[4].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[4],fontweight=\"bold\")\n",
    "ax4.set_ylabel('Loss')\n",
    "ax4.set_xlabel('epoch')\n",
    "ax4.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "ax4.legend()\n",
    "        \n",
    "ax5 = fig.add_subplot(n_optimizers,1,6)\n",
    "ax5.plot(range(1,len(histories[5].history['loss'])+1), histories[5].history['val_loss'],label='val_loss')\n",
    "ax5.plot(range(1,len(histories[5].history['loss'])+1), histories[5].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[5],fontweight=\"bold\")\n",
    "ax5.set_ylabel('Loss')\n",
    "ax5.set_xlabel('epoch')\n",
    "ax5.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "ax5.legend()\n",
    "        \n",
    "ax6 = fig.add_subplot(n_optimizers,1,7)\n",
    "ax6.plot(range(1,len(histories[6].history['loss'])+1), histories[6].history['val_loss'],label='val_loss')\n",
    "ax6.plot(range(1,len(histories[6].history['loss'])+1), histories[6].history['loss'], label='loss')\n",
    "plt.title('Optimizer = '+optimizers[6],fontweight=\"bold\")\n",
    "ax6.set_ylabel('Loss')\n",
    "ax6.set_xlabel('epoch')\n",
    "ax6.grid(True)\n",
    "\n",
    "ax6.legend()\n",
    "\n",
    "plt.show()  \n",
    "plt.savefig('learning_curve.png')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
