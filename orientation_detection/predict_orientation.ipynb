{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is for calling functions to train models and run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from orientation_detection.NN_module import get_CNN, calculate_accuracy, calculate_angle_accuracy, get_FCNN, train_model, get_prediction,plot_learning_curves\n",
    "from orientation_detection.render_images import get_images, get_train_val, show_images\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import keras\n",
    "import time\n",
    "import datetime\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "logdir = os.path.join(root_logdir, \"run_{}\".format(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set general parameters and get Training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set parameters\n",
    "#batch_size defines the number of samples for one forward and back propagation\n",
    "#epochs  is number of one forward pass and backward pass of all the training batches\n",
    "target_type = 'vectorOrientations'\n",
    "image_size = 64\n",
    "num_images = 10000\n",
    "\n",
    "# Get Training and Validation data (Can choose from saved training images or render new images)\n",
    "rendered_images = get_images(num_images,image_size)\n",
    "#rendered_images = pickle.load(open('train_shine_10000_blur07.pkl','rb'))\n",
    "\n",
    "# convert into x_train, xVal, yTrain and yVal\n",
    "xTrain, xVal, yTrain, yVal= get_train_val(rendered_images,target_type)\n",
    "\n",
    "#Getting the images for testing (Can choose from saved test images or render new images)\n",
    "image_test = get_images(1000,image_size)\n",
    "#with open('test_shine_'+str(len(image_test['images']))+'_blur07.pkl','wb') as f:   \n",
    "#    pickle.dump(image_test, f)\n",
    "\n",
    "x_test = np.array(image_test['images'])\n",
    "y_test = np.array([np.concatenate(x) for x in image_test['vectorOrientations']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CNN\n",
    "### 1.1 Build model and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_conv = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'batch_size':30,\n",
    "    'epochs':50,\n",
    "    'conv':[[96,11,'relu'],[384,5,'relu'],[256,5,'relu']],\n",
    "    'padding':['same','same'],  ## padding for conv layer 1 Try with padding same or valid\n",
    "    'maxpool':[2,2,2],  \n",
    "    'FC':[[256,'relu'],[512,'relu']],\n",
    "    'dropout':[0.0,0.2],\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'rmsprop' \n",
    "}\n",
    "\n",
    "parameters_conv2 = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'batch_size':30,\n",
    "    'epochs':50,\n",
    "    'conv':[[96,11,'relu'],[384,5,'relu'],[256,5,'relu']],\n",
    "    'padding':['same','same'],  ## padding for conv layer 1 and 2 Try with padding same or valid\n",
    "    'maxpool':[2,2,2],  \n",
    "    'FC':[[1024,'relu'],[256,'relu']],\n",
    "    'dropout':[0.5,0.3],\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'rmsprop' \n",
    "}\n",
    "\n",
    "# can change the list to whichever parameter we want to train the model with\n",
    "parameters_CNN = [parameters_conv,parameters_conv2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training model for every parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in parameters_CNN:\n",
    "    #filename for the name your model and history\n",
    "    filename = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "    ML_type = 'conv'\n",
    "\n",
    "    #run the training\n",
    "    history = train_model(filename,np.array(xTrain), np.array(xVal), yTrain, yVal, ML_type,parameter)\n",
    "\n",
    "    #plot the learning_curves\n",
    "    plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 CNN Run Prediction with selected model and show pair of images (test image and prediction)\n",
    "- will also return RMSE and angle discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "#Please change the model_filename to load the correct model\n",
    "model_filename = '../trained_model/new_chair/CNN/CNN_model_2019-04-13 22:002019-04-13 22:00'\n",
    "\n",
    "#Run Prediction\n",
    "predictions = get_prediction(target_type,model_filename,x_test, y_test)\n",
    "\n",
    "#print images from pair of true data and prediction, will also return the RMSE and Angle Discrepancy\n",
    "show_images(y_test,predictions,x_test,target_type,image_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network\n",
    "### 2.1 Build model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_FC = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'batch_size':64,\n",
    "    'epochs':50,\n",
    "    'FC':[[4096,'relu'],[1024,'relu'],[256,'relu']],\n",
    "    'dropout':[0.0,0.0,0.5],\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'adam'\n",
    "}\n",
    "parameters_FC = [param_FC] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training model for every parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in parameters_FC:\n",
    "    #filename for the name your model and history\n",
    "    filename = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "    xTrain_fc = np.array([x.flatten() for x in xTrain])\n",
    "    xVal_fc = np.array([x.flatten() for x in xVal])\n",
    "    ML_type = 'fc'\n",
    "\n",
    "    #run the training \n",
    "    history_fc = train_model(filename,xTrain_fc, xVal_fc, yTrain, yVal, ML_type,parameter)\n",
    "\n",
    "    #plot the learning_curves\n",
    "    plot_learning_curves(history_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 FC Run Prediction with selected model and show pair of images (test image and prediction)\n",
    "- will also return RMSE and angle discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "#Please change the model_filename to load the correct model\n",
    "model_filename_fc = \"trained_model/FC_model_2019-04-12 10:492019-04-12 10:49\"\n",
    "\n",
    "x_test_fc = np.array([x.flatten() for x in image_test['images']])\n",
    "\n",
    "#Run Prediction\n",
    "predictions_fc = get_prediction(target_type,model_filename_fc,x_test_fc, y_test)\n",
    "\n",
    "#print images from pair of true data and prediction\n",
    "show_images(y_test,predictions_fc,x_test_fc,target_type,image_size)\n",
    "\n",
    "#Just validation of manually calculated mse and RMSE\n",
    "mse,rmse = calculate_accuracy(y_test,predictions_fc)\n",
    "print(\"Just for crosschecking, mse and rmse calculated outside of the keras\")\n",
    "print('mse = ', mse)\n",
    "print('rmse =', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGG16\n",
    "### 3.1 Build model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_vgg1 = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'not_freeze': 4, #specify number of vgg which is not going to be freezed for training, 0 means freeze all\n",
    "    'pre_trained':True,\n",
    "    'batch_size':64,\n",
    "    'epochs':30,\n",
    "    'FC':[[1024,'relu'],[512,'relu']],\n",
    "    'dropout':[0.0,0.3],\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'adam', \n",
    "    'learning_rate': 'default',\n",
    "    'preprocessing':'yes',\n",
    "    'loss':'custom',\n",
    "    'note':''\n",
    "}\n",
    "\n",
    "parameters_vgg2 = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'not_freeze': 0, #specify number of vgg which is not going to be freezed for training, 0 means freeze all\n",
    "    'pre_trained':True,\n",
    "    'batch_size':64,\n",
    "    'epochs':30,\n",
    "    'FC':[[1024,'relu'],[512,'relu']],\n",
    "    'dropout':[0.0,0.3],\n",
    "    'output_activation':'tanh',\n",
    "    'optimizer': 'adam', \n",
    "    'learning_rate': 'default',\n",
    "    'preprocessing':'yes',\n",
    "    'loss':'mean_squared_error',\n",
    "    'note':'best parameter, using mean squared error and tanh'\n",
    "}\n",
    "\n",
    "\n",
    "parameters_group= [parameters_vgg1, parameters_vgg2]\n",
    "\n",
    "## To preprocess the image before using vgg16 network\n",
    "xTrain_copy = np.array(xTrain).copy()\n",
    "# prepare the image for the VGG model\n",
    "xTrain_copy = preprocess_input(xTrain_copy)\n",
    "\n",
    "xVal_copy = np.array(xVal).copy()\n",
    "# prepare the image for the VGG model\n",
    "xVal_copy = preprocess_input(xVal_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With preprocessing\n",
    "for parameter in parameters_group:\n",
    "    #filename for the name your model and history \n",
    "    filename = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "    ML_type = 'vgg16'\n",
    "\n",
    "    #run the training\n",
    "    history = train_model(filename,xTrain_copy, xVal_copy, yTrain, yVal, ML_type,parameter)\n",
    "        \n",
    "    #plot the learning_curves\n",
    "    plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG Run Prediction with selected model and show pair of images \n",
    "- will also return RMSE and angle discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "#Please change the model_filename to load the correct model\n",
    "model_filename='../trained_model/new_chair/vgg16/vgg16_model_2019-04-18 20:07'\n",
    "\n",
    "#load test data from saved pickle file\n",
    "image_test = pickle.load(open('../Octiba-Nima_files/training data/test_200.pkl','rb'))\n",
    "x_test = np.array(image_test['images'])\n",
    "y_test = np.array([np.concatenate(x) for x in image_test['vectorOrientations']])\n",
    "\n",
    "\n",
    "x_test_copy = x_test.copy()\n",
    "# prepare the image for the VGG model\n",
    "x_test_copy = preprocess_input(x_test_copy)\n",
    "\n",
    "#Run Prediction\n",
    "predictions = get_prediction(target_type,model_filename,x_test_copy, y_test)\n",
    "\n",
    "#print images from pair of true data and prediction\n",
    "show_images(y_test,predictions,x_test,target_type,image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resnet50\n",
    "### 4.1 Build model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_resnet50_1 = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'not_freeze': 21 , #specify number of vgg which is not going to be freezed for training\n",
    "    'pre_trained':True,\n",
    "    'batch_size':64,\n",
    "    'epochs':20,\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'sgd', ## Changed to adamax from adam\n",
    "    'learning_rate': 0.0001,\n",
    "    'preprocessing':'yes'\n",
    "}\n",
    "\n",
    "parameters_resnet50_2 = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'not_freeze': 12, #specify number of vgg which is not going to be freezed for training\n",
    "    'pre_trained':True,\n",
    "    'batch_size':64,\n",
    "    'epochs':20,\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'sgd', ## Changed to adamax from adam\n",
    "    'learning_rate': 0.0001,\n",
    "    'preprocessing':'yes'\n",
    "}\n",
    "\n",
    "parameters_resnet50_3 = {\n",
    "    'image_size':image_size,\n",
    "    'num_images': num_images,\n",
    "    'target_type':'vectorOrientations',\n",
    "    'not_freeze': 16, #specify number of vgg which is not going to be freezed for training\n",
    "    'pre_trained':True,\n",
    "    'batch_size':64,\n",
    "    'epochs':50,\n",
    "    'output_activation':'linear',\n",
    "    'optimizer': 'sgd', ## Changed to adamax from adam\n",
    "    'learning_rate': 0.001,\n",
    "    'preprocessing':'yes'\n",
    "}\n",
    "parameters_res = [parameters_resnet50_1,parameters_resnet50_2]\n",
    "\n",
    "\n",
    "## To preprocess the image before using ResNet-50 network\n",
    "xTrain_copy2 = np.array(xTrain).copy()\n",
    "# Preprocess input using preprocess_input from keras.applications.restnet50\n",
    "xTrain_copy2 = keras.applications.resnet50.preprocess_input(xTrain_copy2)\n",
    "\n",
    "xVal_copy2 = np.array(xVal).copy()\n",
    "# prepare the image for the VGG model\n",
    "xVal_copy2 = keras.applications.resnet50.preprocess_input(xVal_copy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training for each set of parameter\n",
    "for parameter in parameters_res:\n",
    "    \n",
    "    filename = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "    ML_type = 'resnet50'\n",
    "\n",
    "    #run the training and prediction\n",
    "    history = train_model(filename,xTrain_copy2, xVal_copy2, yTrain, yVal, ML_type,parameter)\n",
    "    \n",
    "    #plot the learning_curves\n",
    "    plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To test the model on real Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Getting the x_test\n",
    "arr = os.listdir('../cropped_image/')\n",
    "#cropped = [cv2.resize(np.load('../cropped_image/'+x)[0],(32,32)) for x in arr]\n",
    "cropped = [np.load('../cropped_image/'+x)[0] for x in arr]\n",
    "x_test = [cv2.cvtColor(x,cv2.COLOR_BGR2RGB) for x in cropped]\n",
    "\n",
    "#Load saved model\n",
    "#Please change the model_filename to load the correct model\n",
    "model_filename = '../trained_model/new_chair/vgg16/To_be_tested_16_april/2019-04-15 23:53/vgg16_model_2019-04-15 23:53'\n",
    "\n",
    "#Documents/Myfolders/Lectures/DataMining/trained_model/new_chair/vgg16/To_be_tested_16_april/2019-04-15 23:53/vgg16_model_2019-04-15 23:53\n",
    "model = load_CNN_model('vectorOrientations',model_filename)\n",
    "#Run Prediction\n",
    "predictions = model.predict(preprocess_input(np.array(x_test).copy()))\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    print('====================================================================================================')\n",
    "    plt.imshow(x_test[i].reshape(image_size,image_size,3))\n",
    "    plt.show()\n",
    "    predicted_image = get_images(1,image_size,vectorOrientation=predictions[i].reshape(2,3))\n",
    "    plt.imshow(np.array(predicted_image['images']).astype(int).reshape(image_size,image_size,3))    \n",
    "    plt.show()\n",
    "    print('====================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
